{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON input\n",
    "with open('input.json', 'r') as f:\n",
    "    input_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_path = input_data['design_state_data']['session_info']['dataset']\n",
    "if os.path.exists(dataset_path):\n",
    "    data = pd.read_csv(dataset_path)\n",
    "else:\n",
    "    raise FileExistsError(\"The Specified CSV not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "target_column = input_data['design_state_data']['target']['target']\n",
    "X = data\n",
    "y = data[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'petal_width'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Features One by One since What to with them can vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_to_handle = input_data['design_state_data']['feature_handling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_numericals(strategy, value):\n",
    "    if strategy == \"Average of values\":\n",
    "        strategy = \"mean\"\n",
    "        imputer = SimpleImputer(strategy=strategy )\n",
    "    else:\n",
    "        strategy = \"constant\"\n",
    "        imputer = SimpleImputer(strategy=strategy ,  fill_value=value)\n",
    "    return imputer\n",
    "\n",
    "def scale_numericals(rescaling):\n",
    "    if rescaling == \"No rescaling\":\n",
    "        return None\n",
    "    else:\n",
    "        return StandardScaler()\n",
    "\n",
    "def hash_text(columns):\n",
    "    if columns == 0:\n",
    "        columns = 1\n",
    "    return  HashingVectorizer(n_features=columns, alternate_sign=False, norm=None)\n",
    "def iterate_features_and_handle(all_features_to_handle, X):\n",
    "    numeric_features = []\n",
    "    numeric_transformers = []\n",
    "    categorical_features = []\n",
    "    categorical_transformers = []\n",
    "    for feature, details in all_features_to_handle.items():\n",
    "        #Purposfully avoiding to process The TargetVariable not sure, why it was added to the Handle Features Json\n",
    "        if details['is_selected'] :\n",
    "            #classify it as categorical or Numerical\n",
    "            if details['feature_variable_type'] == 'numerical':\n",
    "                numeric_features.append(feature)\n",
    "                imputer = impute_numericals(strategy=details['feature_details']['impute_with'], value = details['feature_details']['impute_value'])\n",
    "                scaler = scale_numericals(rescaling = details['feature_details']['rescaling'])\n",
    "                transformers = [('imputer', imputer)]\n",
    "                numeric_transformers.append((feature, Pipeline(transformers)))\n",
    "            elif details['feature_variable_type'] == 'text':\n",
    "                categorical_features.append(feature)\n",
    "                text_vectorizer = hash_text(details['feature_details']['hash_columns'])\n",
    "                categorical_transformers.append((feature, text_vectorizer, feature))\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('numeric', Pipeline(numeric_transformers), numeric_features),\n",
    "        ('categorical', ColumnTransformer(transformers=categorical_transformers), categorical_features)])    \n",
    "    columns = X.columns\n",
    "\n",
    "    return  pd.DataFrame(preprocessor.fit_transform(X), columns=columns)\n",
    "\n",
    "\n",
    "\n",
    "X = iterate_features_and_handle(all_features_to_handle, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_generate = input_data['design_state_data']['feature_generation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(dataset, feature_generation):\n",
    "    # Linear interactions\n",
    "    linear_interactions = feature_generation.get(\"linear_interactions\", [])\n",
    "    for interaction in linear_interactions:\n",
    "        dataset[f\"{interaction[0]}_{interaction[1]}\"] = dataset[interaction[0]] * dataset[interaction[1]]\n",
    "\n",
    "    # Polynomial interactions\n",
    "    polynomial_interactions = feature_generation.get(\"polynomial_interactions\", [])\n",
    "    poly = PolynomialFeatures(include_bias=False)\n",
    "    for interaction in polynomial_interactions:\n",
    "        interaction_split = interaction.split(\"/\")\n",
    "        transformed = poly.fit_transform(dataset[[interaction_split[0], interaction_split[1]]])\n",
    "        for i in range(transformed.shape[1]):\n",
    "            dataset[f\"poly_{interaction_split[0]}_{interaction_split[1]}_{i}\"] = transformed[:, i]\n",
    "\n",
    "    # Explicit pairwise interactions\n",
    "    explicit_pairwise_interactions = feature_generation.get(\"explicit_pairwise_interactions\", [])\n",
    "    for interaction in explicit_pairwise_interactions:\n",
    "        interaction_split = interaction.split(\"/\")\n",
    "        dataset[f\"{interaction_split[0]}_{interaction_split[1]}\"] = dataset[interaction_split[0]] * dataset[interaction_split[1]]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "x_generated = generate_features(X,features_to_generate )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_reduction_json  = input_data['design_state_data']['feature_reduction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_features(dataset, config, target_variable):\n",
    "    if config[\"feature_reduction_method\"] == \"Tree-based\":\n",
    "        num_of_features_to_keep = int(config[\"num_of_features_to_keep\"])\n",
    "        num_of_trees = int(config[\"num_of_trees\"])\n",
    "        depth_of_trees = int(config[\"depth_of_trees\"])\n",
    "        \n",
    "        # Select features and target variable\n",
    "        X = dataset.drop(columns=[target_variable])\n",
    "        y = dataset[target_variable]\n",
    "        \n",
    "        # Initialize Random Forest Regressor\n",
    "        rf = RandomForestRegressor(n_estimators=num_of_trees, max_depth=depth_of_trees, random_state=42)\n",
    "        \n",
    "        # Fit Random Forest model\n",
    "        rf.fit(X, y)\n",
    "        \n",
    "        # Get feature importances\n",
    "        feature_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "        \n",
    "        # Select top k features\n",
    "        top_features = feature_importances.nlargest(num_of_features_to_keep).index.tolist()\n",
    "        \n",
    "        # Update dataset with selected features\n",
    "        dataset = dataset[top_features + [target_variable]]\n",
    "        \n",
    "        return dataset\n",
    "    else:\n",
    "        print(\"Unsupported feature reduction method. Please choose 'Tree-based'.\")\n",
    "\n",
    "reduced_features = reduce_features(x_generated, feature_reduction_json, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poly_petal_length_sepal_width_0</th>\n",
       "      <th>petal_width_sepal_length</th>\n",
       "      <th>poly_petal_width_species_0</th>\n",
       "      <th>poly_petal_width_species_3</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.4</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.2</td>\n",
       "      <td>15.41</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11.97</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>5.2</td>\n",
       "      <td>13.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.4</td>\n",
       "      <td>14.26</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.1</td>\n",
       "      <td>10.62</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     poly_petal_length_sepal_width_0  petal_width_sepal_length  \\\n",
       "0                                1.4                      1.02   \n",
       "1                                1.4                      0.98   \n",
       "2                                1.3                      0.94   \n",
       "3                                1.5                      0.92   \n",
       "4                                1.4                      1.00   \n",
       "..                               ...                       ...   \n",
       "145                              5.2                     15.41   \n",
       "146                              5.0                     11.97   \n",
       "147                              5.2                     13.00   \n",
       "148                              5.4                     14.26   \n",
       "149                              5.1                     10.62   \n",
       "\n",
       "     poly_petal_width_species_0  poly_petal_width_species_3  petal_width  \n",
       "0                           0.2                         0.4          0.2  \n",
       "1                           0.2                         0.4          0.2  \n",
       "2                           0.2                         0.4          0.2  \n",
       "3                           0.2                         0.4          0.2  \n",
       "4                           0.2                         0.4          0.2  \n",
       "..                          ...                         ...          ...  \n",
       "145                         2.3                         4.6          2.3  \n",
       "146                         1.9                         3.8          1.9  \n",
       "147                         2.0                         4.0          2.0  \n",
       "148                         2.3                         4.6          2.3  \n",
       "149                         1.8                         3.6          1.8  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jtm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
